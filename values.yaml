# ────────────────────────────────────────────────────────────────────────────────
# kube-prometheus-stack (Prometheus, Alertmanager, Grafana)
# ────────────────────────────────────────────────────────────────────────────────
kube-prometheus-stack:
  fullnameOverride: "kps"   # keeps stable names (e.g., kps-thanos-discovery)

  grafana:
    enabled: true
    adminUser: admin
    # adminPassword: "changeme"

    # EXPOSE GRAFANA VIA NODEPORT
    service:
      type: NodePort
      port: 80
      nodePort: 32000

    # Add Thanos + Loki + Tempo as datasources
    additionalDataSources:
      - name: Thanos
        uid: thanos
        type: prometheus
        access: proxy
        url: http://thanos-query.monitoring.svc.cluster.local:10902
        isDefault: false
        jsonData:
          httpMethod: POST

      - name: Loki
        uid: loki
        type: loki
        access: proxy
        url: http://loki.monitoring.svc.cluster.local:3100
        isDefault: false

      - name: Tempo
        uid: tempo
        type: tempo
        access: proxy
        url: http://tempo.monitoring.svc.cluster.local:3200
        jsonData:
          httpMethod: GET
          tracesToLogs:
            datasourceUid: loki
            mapTagNamesEnabled: true
            tags: ["namespace", "pod", "container"]
          serviceMap:
            datasourceUid: thanos  # or point to Prometheus if you prefer

  prometheus:
    thanosService:
      enabled: true    # exposes gRPC (10901) / HTTP (10902) for the sidecar

    # EXPOSE PROMETHEUS VIA NODEPORT
    service:
      type: NodePort
      port: 9090
      targetPort: 9090
      nodePort: 32090

    prometheusSpec:
      externalLabels:
        cluster: "cluster-a"
      thanos:
        image: "quay.io/thanos/thanos:v0.39.2"
        version: "v0.39.2"

      # Ensure Prometheus will pick up *all* ServiceMonitors/PodMonitors
      serviceMonitorSelectorNilUsesHelmValues: true
      podMonitorSelectorNilUsesHelmValues: true

      # allow operator to pick up ScrapeConfig CRDs from anywhere
      scrapeConfigSelector: {}
      scrapeConfigNamespaceSelector: {}


# ────────────────────────────────────────────────────────────────────────────────
# Bitnami Thanos (Query only)
# ────────────────────────────────────────────────────────────────────────────────
thanos:
  fullnameOverride: "thanos"
  image:
    registry: quay.io
    repository: thanos/thanos
    tag: v0.39.2
    pullPolicy: IfNotPresent
  query:
    enabled: true
    replicaCount: 1
    service:
      type: NodePort
      ports: { http: 9090 }
      nodePorts: { http: 32190 }
    serviceGrpc:
      type: NodePort
      ports: { grpc: 10901 }
      nodePorts: { grpc: 32191 }
    dnsDiscovery:
      enabled: true
      sidecarsService: "kps-thanos-discovery"
      sidecarsNamespace: "monitoring"
  bucketweb: { enabled: false }
  compactor: { enabled: false }
  storegateway: { enabled: false }
  ruler: { enabled: false }
  receive: { enabled: false }
  queryFrontend: { enabled: false }
##############################################################
loki:                                  # subchart alias (from Chart.yaml)
  enabled: true
  fullnameOverride: loki
  deploymentMode: SingleBinary

  # one loki pod with a PVC
  singleBinary:
    replicas: 1
    persistence:
      enabled: true
      size: 20Gi
      # storageClassName: <your-sc>   # optional

  # absolutely disable all scalable roles
  read:    { replicas: 0 }
  write:   { replicas: 0 }
  backend: { replicas: 0 }
  gateway: { enabled: false }

  # disable caches & canary to avoid extra pods / resource pressure
  chunksCache:  { enabled: false }
  resultsCache: { enabled: false }
  canary:       { enabled: false }

  serviceMonitor: { enabled: true }

  loki:                                # nested config consumed by grafana/loki
    # keep 'common' minimal and consistent
    commonConfig:
      replication_factor: 1
      path_prefix: /var/loki

    # satisfy chart helpers; not using object store
    storage:
      use_thanos_objstore: false
      bucketNames:
        chunks: chunks
        ruler:  ruler
        admin:  admin

    auth_enabled: false

    # Filesystem-backed schema (dev/POC)
    schemaConfig:
      configs:
        - from: "2025-01-01"
          store: boltdb
          object_store: filesystem
          schema: v11
          index:
            prefix: index_
            period: 24h

    storage_config:
      boltdb:
        directory: /var/loki/index
      filesystem:
        directory: /var/loki/chunks

    # IMPORTANT: let the chart’s default Memberlist ring stay in place.
    # (Do NOT set ring.kvstore: inmemory here; that conflicts with the default memberlist section.)

    # optional retention for dev
    limits_config:
      allow_structured_metadata: false
      retention_period: 168h
    chunk_store_config:
      max_look_back_period: 168h

# tableManager is top-level in this chart
tableManager:
  retention_deletes_enabled: true
  retention_period: 168h

# ────────────────────────────────────────────────────────────────────────────────
# TEMPO (local storage for dev/POC)
# ────────────────────────────────────────────────────────────────────────────────
tempo:
  enabled: true
  fullnameOverride: tempo
  serviceMonitor: { enabled: true }
  tempo:
    storage:
      trace:
        backend: local
        local: { path: /var/tempo/traces }
  persistence:
    enabled: true
    size: 20Gi
